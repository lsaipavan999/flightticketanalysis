{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4ed854",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing the libraries \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Importing the libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore harmless warnings \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set to display all the columns in dataset\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Import psql to run queries \n",
    "\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfdata = pd.read_csv(r\"C:\\Users\\k.leelasaipavan\\Desktop\\project\\hflights.csv\",header=0)\n",
    "hfdata_bk=hfdata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723fcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48cfc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del hfdata['CancellationCode']\n",
    "del hfdata['TailNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer_knn = KNNImputer(missing_values=np.nan)\n",
    "\n",
    "# Fill the missing values for 'Driver_Age'\n",
    "\n",
    "hfdata['DepTime'] = imputer_knn.fit_transform(hfdata[['DepTime']])\n",
    "hfdata['ArrTime'] = imputer_knn.fit_transform(hfdata[['ArrTime']])\n",
    "#hfdata['TailNum'] = imputer_knn.fit_transform(hfdata[['TailNum']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer_str = SimpleImputer(missing_values=np.nan, strategy='most_frequent', fill_value=None,\n",
    "                            verbose=0,copy=True, add_indicator=False)\n",
    "hfdata['ActualElapsedTime'] = imputer_str.fit_transform(hfdata[['ActualElapsedTime']])\n",
    "hfdata['AirTime'] = imputer_str.fit_transform(hfdata[['AirTime']])\n",
    "hfdata['ArrDelay'] = imputer_str.fit_transform(hfdata[['ArrDelay']])\n",
    "hfdata['DepDelay'] = imputer_str.fit_transform(hfdata[['DepDelay']])\n",
    "hfdata['TaxiIn'] = imputer_str.fit_transform(hfdata[['TaxiIn']])\n",
    "hfdata['TaxiOut'] = imputer_str.fit_transform(hfdata[['TaxiOut']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f7e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfdata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b8ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LabelEncoder to handle categorical data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE = LabelEncoder()\n",
    "\n",
    "hfdata['UniqueCarrier'] = LE.fit_transform(hfdata[['UniqueCarrier']])\n",
    "hfdata['Origin'] = LE.fit_transform(hfdata[['Origin']])\n",
    "hfdata['Dest'] = LE.fit_transform(hfdata[['Dest']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hfdata['CancellationCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b4071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d773ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "IndepVar = []\n",
    "for col in hfdata.columns:\n",
    "    if col != 'Cancelled':\n",
    "        IndepVar.append(col)\n",
    "TargetVar = 'Cancelled'\n",
    "x=hfdata[IndepVar]\n",
    "y=hfdata[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a99115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state = 42)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b534f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train_scaled = mmscaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_scaled)\n",
    "\n",
    "x_test_scaled = mmscaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f156aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_Results = pd.read_csv(r\"C:\\Users\\k.leelasaipavan\\Desktop\\project\\hf_results.csv\",header=0)\n",
    "HF_Results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Calssification models with Over Sampling and compare the results\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# Create objects of classification algorithms with default hyper-parameters\n",
    "\n",
    "ModelLR = LogisticRegression()\n",
    "ModelDC = DecisionTreeClassifier()\n",
    "ModelRF = RandomForestClassifier()\n",
    "ModelKN = KNeighborsClassifier()\n",
    "ModelSVM = SVC(probability=True)\n",
    "ModelET = ExtraTreesClassifier()\n",
    "ModelGNB = GaussianNB()\n",
    "\n",
    "\n",
    "\n",
    "# Evalution matrix for all the algorithms\n",
    "\n",
    "#MM = [ModelLR, ModelDC, ModelRF, ModelET, ModelKNN, ModelGNB, ModelSVM, modelXGB, modelLGB]\n",
    "MM = [ModelLR, ModelDC, ModelRF,ModelKN,ModelSVM,ModelET,ModelGNB]\n",
    "for models in MM:\n",
    "    \n",
    "    # Assign values\n",
    "    \n",
    "    #x_train = xo_train\n",
    "    #x_test = xo_test\n",
    "    #y_train = yo_train\n",
    "    #y_test = yo_test\n",
    "            \n",
    "    # Train the model training dataset\n",
    "    \n",
    "    models.fit(x_train, y_train)\n",
    "    \n",
    "    # Prediction the model with test dataset\n",
    "    \n",
    "    y_pred = models.predict(x_test)\n",
    "    y_pred_prob = models.predict_proba(x_test)\n",
    "    \n",
    "    # Print the model name\n",
    "    \n",
    "    print('Model Name: ', models)\n",
    "    \n",
    "    # confusion matrix in sklearn\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    # actual values\n",
    "\n",
    "    actual = y_test\n",
    "\n",
    "    # predicted values\n",
    "\n",
    "    predicted = y_pred\n",
    "\n",
    "    # confusion matrix\n",
    "\n",
    "    matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "    print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "    # outcome values order in sklearn\n",
    "\n",
    "    tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "    print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "    # classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "    C_Report = classification_report(actual,predicted,labels=[1,0])\n",
    "\n",
    "    print('Classification report : \\n', C_Report)\n",
    "\n",
    "    # calculating the metrics\n",
    "\n",
    "    sensitivity = round(tp/(tp+fn), 3);\n",
    "    specificity = round(tn/(tn+fp), 3);\n",
    "    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "    balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "    precision = round(tp/(tp+fp), 3);\n",
    "    f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "    # Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "    # A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "    #from math import sqrt\n",
    "\n",
    "    #mx = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "    #MCC = round(((tp * tn) - (fp * fn)) / sqrt(mx), 3)\n",
    "\n",
    "    print('Accuracy :', round(accuracy*100, 2),'%')\n",
    "    print('Precision :', round(precision*100, 2),'%')\n",
    "    print('Recall :', round(sensitivity*100,2), '%')\n",
    "    print('F1 Score :', f1Score)\n",
    "    print('Specificity or True Negative Rate :', round(specificity*100,2), '%'  )\n",
    "    print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')\n",
    "    #print('MCC :', MCC)\n",
    "\n",
    "    # Area under ROC curve \n",
    "\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "    print('roc_auc_score:', round(roc_auc_score(actual, y_pred), 3))\n",
    "    \n",
    "    # ROC Curve\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import roc_curve\n",
    "    Model_roc_auc = roc_auc_score(actual, y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(actual, models.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    #\n",
    "    plt.plot(fpr, tpr, label= 'Classification Model' % Model_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()\n",
    "    print('-----------------------------------------------------------------------------------------------------')\n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "    new_row = {'Model Name' : models,\n",
    "               'True Positive': tp,\n",
    "               'False Negative': fn, \n",
    "               'False Positive': fp, \n",
    "               'True Negative': tn,\n",
    "               'Accuracy' : accuracy,\n",
    "               'Precision' : precision,\n",
    "               'Recall' : sensitivity,\n",
    "               'F1 Score' : f1Score,\n",
    "               'Specificity' : specificity,\n",
    "               'MCC': 'MCC',\n",
    "               'ROC_AUC_Score':roc_auc_score(actual, y_pred),\n",
    "               'Balanced Accuracy':balanced_accuracy}\n",
    "    HF_Results = HF_Results.append(new_row, ignore_index=True)\n",
    "    #----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c172eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_Results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_Results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9947d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
